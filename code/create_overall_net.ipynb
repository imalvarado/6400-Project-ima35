{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import copy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nodes(G, results_df):\n",
    "\n",
    "    names = results_df[\"Name\"]\n",
    "    for name in names:\n",
    "        if name not in list(G.nodes()):\n",
    "            G.add_node(name)\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "def add_event_results(G, results_df, event_name):\n",
    "\n",
    "    event_results = results_df[[\"Name\", event_name]].dropna()\n",
    "    rankings = list(event_results[event_name].unique())\n",
    "    rankings.sort(reverse=True)\n",
    "\n",
    "    for rank in rankings[:-1]:\n",
    "        \n",
    "        # GET SURFERS WHO FINISHED WITH RANK\n",
    "        rank_batch = event_results[event_results[event_name] == rank]\n",
    "        rank_surfers = list(rank_batch[\"Name\"])\n",
    "        \n",
    "        # REMOVE SURFERS WITH RANK FROM RESULTS DATAFRAME\n",
    "        event_results = event_results[~event_results[\"Name\"].isin(rank_surfers)]\n",
    "        remaining_surfers = list(event_results[\"Name\"])\n",
    "\n",
    "        # CREATE EDGES FOR SURFERS WITH RANK\n",
    "        for rank_surfer in rank_surfers:\n",
    "            for other_surfer in remaining_surfers:\n",
    "\n",
    "                # CASE WHERE EDGE ALREADY EXISTS\n",
    "                if G.has_edge(rank_surfer, other_surfer):\n",
    "                    G[rank_surfer][other_surfer][\"weight\"] += 1\n",
    "\n",
    "                # CASE WHERE EDGE DOES NOT EXIST\n",
    "                else:\n",
    "                    G.add_edge(rank_surfer, other_surfer, weight=1)\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "def visualize_graph(G):\n",
    "\n",
    "    # SET LAYOUT\n",
    "    pos = nx.spring_layout(G, k=1, iterations=20)\n",
    "\n",
    "    # GET NODE INFO\n",
    "    in_degrees = dict(G.in_degree())\n",
    "\n",
    "    # SET NODE SIZING\n",
    "    node_sizes = [in_degrees[node]*30 for node in G.nodes()]\n",
    "\n",
    "    # DRAW NETWORK\n",
    "    nx.draw(G,\n",
    "        node_size=node_sizes,\n",
    "        pos=pos\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def condense_edge(G, n1, n2):\n",
    "\n",
    "    # GET NODE WEIGHTS\n",
    "    try:\n",
    "        n1_n2 = G.get_edge_data(n1, n2)[\"weight\"]\n",
    "        n2_n1 = G.get_edge_data(n2, n1)[\"weight\"]\n",
    "    except:\n",
    "        return G\n",
    "\n",
    "    # GET DIFF.\n",
    "    diff = n1_n2 - n2_n1\n",
    "\n",
    "    # REMOVE EDGES\n",
    "    G.remove_edges_from([(n1, n2), (n2, n1)])\n",
    "\n",
    "    # ADD NET EDGE\n",
    "    if diff > 0:\n",
    "        G.add_edge(n1, n2, weight=diff)\n",
    "    elif diff < 0:\n",
    "        G.add_edge(n2, n1, weight=-diff)\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "def condense_all_edges(G):\n",
    "\n",
    "    # GET ALL NODES\n",
    "    all_nodes = list(G.nodes())\n",
    "\n",
    "    # GET NODE PAIRS\n",
    "    all_pairs = list(itertools.combinations(all_nodes, 2))\n",
    "\n",
    "    # ITERATE OVER PAIRS\n",
    "    for pair in all_pairs:\n",
    "        G = condense_edge(G, pair[0], pair[1])\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create network for results from all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET YEAR RANGE\n",
    "first_year = 2010; last_year = 2019\n",
    "years = [str(y) for y in range(first_year, last_year+1)]\n",
    "\n",
    "# INITIALIZE GRAPH\n",
    "results_net = nx.DiGraph()\n",
    "\n",
    "# LOOP OVER YEARS\n",
    "for year in years:\n",
    "\n",
    "    # LOAD DATA\n",
    "    results_df = pd.read_csv(f\"../data/results_data/wsl_results_{year}.csv\")\n",
    "\n",
    "    # UPDATE NODES\n",
    "    update_nodes(results_net, results_df)\n",
    "\n",
    "    # ADD RESULTS FOR ALL EVENTS\n",
    "    events = list(results_df.drop(\"Name\", axis=1).columns)\n",
    "    for event in events:\n",
    "        results_net = add_event_results(results_net, results_df, event)\n",
    "\n",
    "# CONDENSE EDGES USING NET WEIGHTS\n",
    "results_net = condense_all_edges(results_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE NETWORK\n",
    "nx.write_gml(results_net, \"../data/networks/overall_results_network.gml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
