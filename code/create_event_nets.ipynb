{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nodes(G, results_df):\n",
    "\n",
    "    names = results_df[\"Name\"]\n",
    "    for name in names:\n",
    "        if name not in list(G.nodes()):\n",
    "            G.add_node(name, events=1)\n",
    "        else:\n",
    "            G.nodes[name][\"events\"] += 1\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "def add_event_results(G, results_df, event_name):\n",
    "\n",
    "    event_results = results_df[[\"Name\", event_name]].dropna()\n",
    "    rankings = list(event_results[event_name].unique())\n",
    "    rankings.sort(reverse=True)\n",
    "\n",
    "    for rank in rankings[:-1]:\n",
    "        \n",
    "        # GET SURFERS WHO FINISHED WITH RANK\n",
    "        rank_batch = event_results[event_results[event_name] == rank]\n",
    "        rank_surfers = list(rank_batch[\"Name\"])\n",
    "        \n",
    "        # REMOVE SURFERS WITH RANK FROM RESULTS DATAFRAME\n",
    "        event_results = event_results[~event_results[\"Name\"].isin(rank_surfers)]\n",
    "        remaining_surfers = list(event_results[\"Name\"])\n",
    "\n",
    "        # CREATE EDGES FOR SURFERS WITH RANK\n",
    "        for rank_surfer in rank_surfers:\n",
    "            for other_surfer in remaining_surfers:\n",
    "\n",
    "                # CASE WHERE EDGE ALREADY EXISTS\n",
    "                if G.has_edge(rank_surfer, other_surfer):\n",
    "                    G[rank_surfer][other_surfer][\"weight\"] += 1\n",
    "\n",
    "                # CASE WHERE EDGE DOES NOT EXIST\n",
    "                else:\n",
    "                    G.add_edge(rank_surfer, other_surfer, weight=1)\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "# def update_nodes(G, results_df):\n",
    "\n",
    "#     names = results_df[\"Name\"]\n",
    "#     for name in names:\n",
    "#         if name not in list(G.nodes()):\n",
    "#             G.add_node(name)\n",
    "#     return G\n",
    "\n",
    "\n",
    "\n",
    "# def add_event_results(G, results_df, event_name):\n",
    "\n",
    "#     event_results = results_df[[\"Name\", event_name]].dropna()\n",
    "#     rankings = list(event_results[event_name].unique())\n",
    "#     rankings.sort(reverse=True)\n",
    "\n",
    "#     for rank in rankings[:-1]:\n",
    "        \n",
    "#         # GET SURFERS WHO FINISHED WITH RANK\n",
    "#         rank_batch = event_results[event_results[event_name] == rank]\n",
    "#         rank_surfers = list(rank_batch[\"Name\"])\n",
    "        \n",
    "#         # REMOVE SURFERS WITH RANK FROM RESULTS DATAFRAME\n",
    "#         event_results = event_results[~event_results[\"Name\"].isin(rank_surfers)]\n",
    "#         remaining_surfers = list(event_results[\"Name\"])\n",
    "\n",
    "#         # CREATE EDGES FOR SURFERS WITH RANK\n",
    "#         for rank_surfer in rank_surfers:\n",
    "#             for other_surfer in remaining_surfers:\n",
    "\n",
    "#                 # CASE WHERE EDGE ALREADY EXISTS\n",
    "#                 if G.has_edge(rank_surfer, other_surfer):\n",
    "#                     G[rank_surfer][other_surfer][\"weight\"] += 1\n",
    "\n",
    "#                 # CASE WHERE EDGE DOES NOT EXIST\n",
    "#                 else:\n",
    "#                     G.add_edge(rank_surfer, other_surfer, weight=1)\n",
    "\n",
    "#     return G\n",
    "\n",
    "\n",
    "\n",
    "def condense_edge(G, n1, n2):\n",
    "\n",
    "    # GET NODE WEIGHTS\n",
    "    try:\n",
    "        n1_n2 = G.get_edge_data(n1, n2)[\"weight\"]\n",
    "        n2_n1 = G.get_edge_data(n2, n1)[\"weight\"]\n",
    "    except:\n",
    "        return G\n",
    "\n",
    "    # GET DIFF.\n",
    "    diff = n1_n2 - n2_n1\n",
    "\n",
    "    # REMOVE EDGES\n",
    "    G.remove_edges_from([(n1, n2), (n2, n1)])\n",
    "\n",
    "    # ADD NET EDGE\n",
    "    if diff > 0:\n",
    "        G.add_edge(n1, n2, weight=diff)\n",
    "    elif diff < 0:\n",
    "        G.add_edge(n2, n1, weight=-diff)\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "def condense_all_edges(G):\n",
    "\n",
    "    # GET ALL NODES\n",
    "    all_nodes = list(G.nodes())\n",
    "\n",
    "    # GET NODE PAIRS\n",
    "    all_pairs = list(itertools.combinations(all_nodes, 2))\n",
    "\n",
    "    # ITERATE OVER PAIRS\n",
    "    for pair in all_pairs:\n",
    "        G = condense_edge(G, pair[0], pair[1])\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create event networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET YEAR RANGE\n",
    "first_year = 2010; last_year = 2019\n",
    "years = [str(y) for y in range(first_year, last_year+1)]\n",
    "\n",
    "event_dict = {}\n",
    "yearly_data = {}\n",
    "\n",
    "# LOOP OVER YEARS\n",
    "for year in years:\n",
    "\n",
    "    # LOAD DATA\n",
    "    results_df = pd.read_csv(f\"../data/results_data/wsl_results_{year}.csv\")\n",
    "    yearly_data[year] = results_df\n",
    "\n",
    "    for colname in results_df.columns:\n",
    "        if colname == \"Name\":\n",
    "            continue\n",
    "\n",
    "        if colname not in list(event_dict.keys()):\n",
    "            event_dict[colname] = 1\n",
    "        else:\n",
    "            event_dict[colname] += 1\n",
    "\n",
    "\n",
    "# KEEP ONLY EVENTS WITH ENOUGH DATA\n",
    "events_to_remove = []\n",
    "for key, value in event_dict.items():\n",
    "    if value <=2:\n",
    "        events_to_remove.append(key)\n",
    "for key in events_to_remove:\n",
    "    del event_dict[key]\n",
    "events = list(event_dict.keys())\n",
    "\n",
    "# LOOP OVER EVENTS\n",
    "for event in events:\n",
    "\n",
    "    # INITIALIZE NETWORK\n",
    "    event_net = nx.DiGraph()\n",
    "    \n",
    "    # LOOP OVER DATAFRAMES FOR EACH YEAR\n",
    "    for key, data in yearly_data.items():\n",
    "\n",
    "        # CHECK IF EVENT IN YEAR\n",
    "        if not event in list(data.columns):\n",
    "            continue\n",
    "\n",
    "        # FILTER TO EVENT\n",
    "        filtered_results = data.filter([\"Name\", event], axis=1)\n",
    "\n",
    "        # GET NODES\n",
    "        event_net = update_nodes(event_net, filtered_results)\n",
    "\n",
    "        # ADD EVENT RESULTS\n",
    "        event_net = add_event_results(event_net, filtered_results, event)\n",
    "\n",
    "    # CONDENSE EDGES USING NET WEIGHT\n",
    "    event_net = condense_all_edges(event_net)\n",
    "\n",
    "    # WRITE NETWORK TO DISK\n",
    "    nx.write_gml(event_net, f\"../data/networks/{event}_results_network.gml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
